Title: Logic and Proof
#+Author: [[http://www.andrew.cmu.edu/user/avigad][Jeremy Avigad]], [[http://www.andrew.cmu.edu/user/rlewis1/][Robert Y. Lewis]],  [[http://www.contrib.andrew.cmu.edu/~fpv/][Floris van Doorn]]

* Functions
:PROPERTIES:
  :CUSTOM_ID: Functions
:END:      

In the late nineteenth century, developments in a number of branches
of mathematics pushed towards a uniform treatment of sets, functions,
and relations. We have already considered sets and relations. In this
chapter, we turn to functions and their properties.

A function, $f$, is ordinary understood as a mapping from one domain,
$A$, to another domain, $B$. In set-theoretic foundations, $A$ and $B$
are arbitrary sets. We have seen that in a type-based system like
Lean, it is natural to distinguish between /types/ and subsets of a
type. In other words, we can consider a type =X= of elements, and a
set =A= of elements of that type. Thus, in the type-theoretic
formulation, it is natural to consider functions between types =X= and
=Y=, and consider their behavior with respect to subsets of =X= and
=Y=.

In everyday mathematics, however, set-theoretic language is common,
and most mathematicians think of a function as a map between
sets. When discussing functions from a mathematical standpoint,
therefore, we will also adopt this language, and later switch to the
type-theoretic representation when we talk about formalization in
Lean.

** The Function Concept

If $A$ and $B$ are any sets, we write $f : A \to B$ to express the
fact that $f$ is a function from $A$ to $B$. This means that $f$
assigns a value $f(x)$ in $B$ to every element $x$ of $A$. The set $A$
is called the /domain/ of $f$, and the set $B$ is called the
/codomain/. (Some authors use the word "range" for the codomain, but
today it is more common to use the word "range" for what we call the
/image/ of $A$ below. We will avoid the ambiguity by avoiding the word
range altogether.)

The simplest way to define a function is to give its value at every
$x$ with an explicit expression. For example, we can write any of the
following:
- Let $f : \NN \to \NN$ be the function defined by $f(n) = n + 1$.
- Let $g : \RR \to \RR$ be the function defined by $g(x) = x^2$.
- Let $h : \NN \to \NN$ be the function defined by $h(n) = n^2$.
- Let $k : \NN \to \{0, 1\}$ be the function defined by
\[
k(n) = 
  \left\{\begin{array}{ll}
    0 & \mbox{if $n$ is even} \\
    1 & \mbox{if $n$ is odd}
  \end{array}\right.
\] 
The ability to define functions using an explicit expression raises
the foundational question as to what counts as legitimate
"expression." For the moment, let us set that question aside, and
simply note that modern mathematics is comfortable with all kinds of
exotic definitions. For example, we can define a function $f : \RR \to
\{0, 1\}$ by
\[
f(x) = 
  \left\{\begin{array}{ll}
    0 & \mbox{if $x$ is rational} \\
    1 & \mbox{if $x$ is irrational}
  \end{array}\right.
\] 
This is at odds with a view of functions as objects that are
computable in some sense. It is not at all clear what it means to be
presented with a real number as input, let alone whether it is
possible to determine, algorithmically, whether such a number is
rational or not. We will return to discuss such issues in a later
chapter.

Notice that the choice of the variables $x$ and $n$ in the definitions
above are arbitrary. They are bound variables in that the functions
being defined do not depend on $x$ or $n$. The values remain the same
under renaming, just as the truth values of "for every $x$, $P(x)$"
and "for every $y$, $P(y)$ are the same. Given an expression $e(x)$
that depends on the variable $x$, logicians often use the notation
$\lam x e(x)$ to denote the function that maps $x$ to $e(x)$. This is
called "lambda notation," for the obvious reason, and it is often
quite handy. Instead of saying "let $f$ be the function defined by
$f(x) = x+1$, we can say "let $f = \lam x (x + 1)$." This is /not/
common mathematical notation, however, and it is best to avoid it
unless you are talking to logicians or computer scientists. We will
see, however, that lambda notation is built in to Lean.

For any set $A$, we can define a function $i_A(x)$ by the equation
$i_A(x) = x$. This function is called the /identity function/. More
interestingly, let $f : A \to B$ and $g : B \to C$. We can define a
new function $k : A \to C$ by $k(x) = g(f(x))$. The function $k$ is
called /the composition of $f$ and $g$/ or /$f$ composed with $g$/ and
it is written $g \circ f$. The order is somewhat confusing; you just
have to keep in mind that to evaluate the expression $g(f(x))$ you
first evaluate $f$ on input $x$, and then evaluate $g$.

We think of two functions $f, g : A \to B$ as being equal, or the same
function, when for they have the same values on every input; in other
words, for every $x$ in $A$, $f(x) = g(x)$. For example, if
$f, g : \RR \to \RR$ are defined by $f(x) = x + 1$ and $g(x) = 1 + x$,
then $f = g$. Notice that the statement that two functions are equal
is a universal statement (that is, for the form "for every $x$, ...").

-----

*Proposition.* For every $f : A \to B$, $f \circ i_A = f$ and $i_B
\circ f = f$.

*Proof.* Let $x$ be any element of $A$. Then $(f \circ i_A)(x) =
f(i_A(x)) = f(x)$, and $(i_B \circ f)(x) = i_B(f(x)) = x$.

-----

Suppose $f : A \to B$ and $g : B \to A$ satisfy $g \circ f =
i_A$. Remember that this means that $g(f(x)) = x$ for every $x$ in
$A$. In that case, $g$ is said to be a /left inverse/ to $f$, and $f$
is said to be a /right inverse/ to $g$. Here are some examples:
- Define $f, g : \RR \to \RR$ by $f(x) = x + 1$ and $g(x) = x -
  1$. Then $g$ is both a left and a right inverse to $f$, and vice-versa.
- Write $\RR^{\geq 0}$ to denote the nonnegative reals. Define 
  $f : \RR \to \RR^{\geq 0}$ by $f(x) = x^2$, and define $g :
  \RR^{\geq 0} \to \RR$ by $g(x) = \sqrt x$. Then $f(g(x)) = (\sqrt
  x)^2 = x$ for every $x$ in the domain of $g$, so $f$ is a left
  inverse to $g$, and $g$ is a right inverse to $f$. On the other
  hand, $g(f(x)) = \sqrt{x^2} = | x |$, which is not the same as $x$
  when $x$ is negative. So $g$ is not a left inverse to $f$, and $f$
  is not a right inverse to $g$.

-----

The following fact is not at all obvious, even though the proof is short:

-----

*Proposition.* Suppose $f : A \to B$ has a left inverse,
$h$, and a right inverse $k$. Then $h = k$.

*Proof.* Let $y$ be any element in $B$. The idea is to compute
$h(f(k(y))$ in two different ways. Since $h$ is a left inverse to $f$,
we ahve $h(f(k(y))) = k(y)$. On the other hand, since $k$ is a right
inverse to $f$, $f(k(y)) = y$, and so $h(f(k(y)) = h(y)$. So $k(y) =
h(y)$.

-----


If $g$ is both a right and left inverse to $f$, we say that $g$ is
simply the inverse of $f$. A function $f$ may have more than one left
or right inverse (we leave it to you to cook up examples), but it can
have at most one inverse.

-----

*Proposition.* Suppose $g_1, g_2 : B \to A$ are both inverse to
$f$. Then $g_1 = g_2$.

*Proof.* The follows from the previous proposition, since (say) $g_1$
is a left inverse to $f$, and $g_2$ is a right inverse.

-----

When $f$ has an inverse, $g$, this justifies calling $g$ /the/ inverse
to $f$, and writing $f^{-1}$ to denote $g$. Notice that if $f^{-1}$ is
an inverse to $f$, then $f$ is an inverse to $f^{-1}$. So if $f$ has
an inverse, then so does $f^{-1}$, and $(f^{-1})^{-1} = f$. For any
set $A$, clearly we have $i_A^{-1} = i_A$.

-----

*Proposition.* Suppose $f : A \to B$ and $g : B \to C$. If $h : B \to A$ is a
left inverse to $f$ and $k : C \to B$ is a left inverse to $g$, then
$h \circ k$ is a left inverse to $g \circ f$.

*Proof.* For every $x$ in $A$,
\[
(h \circ k) \circ (g \circ f) (x) = h(k(g(f(x)) = h(f(x)) = x.
\]

*Corollary.* The previous proposition holds with "left" replaced by
"right".

*Proof.* Switch the role of $f$ with $h$ and $g$ with $k$ in the
previous proposition.

*Corollary.* If $f : A \to B$ and $g : B \to C$ both have inverses,
then $(f \circ g)^{-1} = g^{-1} \circ f^{-1}$.

-----

# some pictures here would be helpful.

** Injective, Surjective, and Bijective Functions

A function $f : A \to B$ is said to be /injective/, or an /injection/,
or /one-one/, if given any $x$ and $y$ in $A$, if $f(x) = f(y)$, then
$x = y$. Notice that the conclusion is equivalent to its
contrapositive: if $x \neq y$, then $f(x) \neq f(y)$. So $f$ is
injective if it maps distinct element of $A$ to distinct elements of
$B$.

A function $f : A \to B$ is said to be /surjective/, or a
/surjection/, or /onto/, if for every element $y$ of $B$, there is an
$x$ in $A$ such that $f(x) = y$. In other words, $f$ is surjective if
every element in the codomain is the value of $f$ at some element in
the domain.

A function $f : A \to B$ is said to be /bijective/, or a /bijection/,
or a /one-to-one correspondence/, if it is both injective and
surjective. Intuitively, if there is a bijection between $A$ and $B$,
then $A$ and $B$ have the same size, since $f$ makes each element of
$A$ correspond to exactly one element of $B$ and vice-versa. For
example, it makes sense to interpret the statement that there were four
Beatles as the statement that there is a bijection between the set
$\{1, 2, 3, 4\}$ and the set $\{ \text{John, Paul, George, Ringo} \}$.
If we claimed that there were /five/ Beatles, as evidenced by the
function $f$ which assigns 1 to John, 2 to Paul, 3 to George, 4 to
Ringo, and 5 to John, you should object that we double-counted John
--- that is, $f$ is not injective. If we claimed there were only three
Beatles, as evidenced by the function $f$ which assigns 1 to John, 2
to Paul, and 3 to George, you should object that we left out poor
Ringo --- that is, $f$ is not surjective.

The next two propositions show that these notions can be cast in
terms of the existence of inverses.

-----

*Proposition.* Let $f : A \to B$.
- If $f$ has a left inverse, then $f$ is injective.
- If $f$ has a right inverse, then $f$ is surjective.
- If $f$ has an inverse, then it is $f$ bijective.

*Proof.* For the first claim, suppose $f$ has a left inverse $g$, and
suppose $f(x_1) = f(x_2)$. Then $g(f(x_1)) = g(f(x_2))$, and so $x_1 =
x_2$.

For the second claim, suppose $f$ has a right inverse $h$. Let $y$ be
any element of $B$, and let $x = g(y)$. Then $f(x) = f(g(y)) = y$.

The third claim follows from the first two.

-----

The following proposition is more interesting, because it requires us
to define new functions, given hypotheses on $f$.

-----

*Proposition.* Let $f : A \to B$.
- If $A$ is nonempty and $f$ is injective, then $f$ has a left
  inverse.
- If $f$ is surjective, then $f$ has a right inverse.
- If $f$ if bijective, then it has an inverse.

*Proof.* For the first claim, let $a$ be any element of $A$, and
suppose $f$ is injective. Define $g : B \to A$ by setting $g(y)$ equal
to any $x$ such that $f(x) = y$, if there is one, and $a$
otherwise. Now, suppose $g(f(x)) = x'$. By the definition of $g$, $x'$
has to have the proepty that $f(x) = f(x')$. Since $f$ is injective,
$x = x'$, so $g(f(x)) = x$.

For the second claim, because $f$ is surjective, we know that for
every $y$ in $B$ there is any $x$ such that $f(x) = y$. Define $h : B
\to A$ by again setting $h(y)$ equal to any such $x$. (In contrast to
the previous paragraph, here we know that such an $x$ exists, but it
might not be unique.) Then, by the definition of $h$, we have $f(h(y))
= y$.

-----

Notice that the definition of $g$ in the first part in the first part
of the proof requires the function to "decide" whether there is an $x$
in $A$ such that $f(x) = y$. There is nothing mathematically dubious
about this definition, but if many situations, this cannot be done
/algorithmically/; in other words, $g$ might not be computable from
the data. More interestingly, the definition of $h$ in the second part
of the proof requires the function to "choose" a suitale value of $x$ from
among potentially many candidates. We will see later that this is a
version of the /axiom of choice/. In the early twentieth century, the
use of the axiom of choice in mathematics was hotly debated, but today
it is commonplace.

Using these equivalances and the results in the previous section, we
can prove the following:

-----

*Proposition.* Let $f : A \to B$ and $g : B \to C$.
- if $f$ and $g$ are injective, then so is $g \circ f$.
- if $f$ and $g$ are surjective, then so is $g \circ f$.

*Proof.* If $f$ and $g$ are injective, then they have left inverses
$h$ and $k$, respectively, in which case $h \circ k$ is a left inverse
to $g \circ f$. The second statement is proved similarly.

-----

Once can prove these two statements, however, without mentioning
inverses at all. We leave that to you as an exercise.

Notice that the expression $f(n) = 2 n$ can be used to define
infinitely many functions with domain $\NN$, such as:
- a function $f : \NN \to \NN$
- a function $f : \NN \to \RR$
- a function $f: \NN \to \{ n \; | \; n \text{is even} \}$
Only the third one is surjective. Thus a specification of the
function's codomain as well as the domain is essential to making sense
of whether a function is surjective. 

** Functions and Subsets of the Domain

Restriction. If $f : A \to B$ and $C \subseteq A$, "$f$ is injective
on $C$" means that the restriction of $f$ to $A$ is injective. 
 
The image of $f[A]$ of a function $f$ on a set $A$. Image of $f$,
range.

Preimage.

** Functions and Relations

# later we should move this to the existential quantifier chapter.

exists unique

A binary relation $R(x,y)$ on $A$ and $B$ is /functional/ if for every
$x$ in $A$ there exists a unique $y$ in $B$ such that $R(x,y)$. If $R$
is a functional relation, we can define a function $f_R : A \to B$ by
setting $f_R(x)$ to be equal to the unique $y$ in $B$ such that
$R(x,y)$. Conversely, it is not hard to see that if $f : A \to B$ is
any function, the relation $R_f(x, y)$ defined by $f(x) = y$ is a
functional relation. The relation $R_f(x,y)$ is known as the /graph/
of $f$.

It is not hard to check that these two operations travel in pairs: if
$f$ is the function associated with a functional relation $R$, then
$R$ is the functional relation associated the function $f$, and
vice-versa. Thus there is a close relationship between functions and
functional relations. In set-theoretic foundations, a function is
often defined /to be/ a functional relation. Conversely, we have seen
that in type-theoretic foundations like the one adopted by Lean,
relations are often defined to be certain types of functions. We will
discuss these matters later on, and in the meanwhile only remark that
in everyday mathematical practice, the foundational details are not so
important; what is important is simply that every function has a
graph, and that any functional relation can be used to define a
corresponding function.

partial functions

functions with multiple arguments

** Functions and Symbolic Logic

Even though we have avoided the use of quantifiers and logical symbols
in the definitions above, by now you should be seeing them lurking
beneath the surface. That fact that two functions $f, g : A \to B$ are
equal if and only if they take the same values at every input can be
expressed as follows:
\[
\fa {x \in A} (f(x) = g(x)) \liff f = g
\]
This principle is a known as /function extensionality/. Notice that
the notation $\fa {x \in A} P(x)$ abbreviates $\fa x (x \in A \to
P(x))$, and $\ex {x \in A} P(x)$ abbreviates $\ex x (x \in A \wedge
P(x))$, thereby relativizing the quantifiers to $A$.

The function $f$ is injective if it satisfies
\[
\fa {x_1, x_2 \in A} (f(x_1) = f(x_2) \to x_1 = x_2),
\]
and $f$ is surjective if
\[
\fa {y \in B} \ex {x \in A} (f(x) = y).
\]
If $f : A \to B$ and $g: B \to A$, $g$ is a left inverse
to $f$ (or, equivalently, that $f$ is a right inverse to $g$) if
\[
\fa {x \in A} g(f(x)) = a,
\]
a universal statement.

Remember that in logic it is common to use lambda notation to define
functions. We can denote the identity function by $\lam x x$, or
perhaps $\lam {x : A,} x$ to emphasize that the domain of the function
is $A$. If $f : A \to B$ and $g : B \to C$, we can define the
composition $g \circ f$ by $g \circ f = \lam {x : A,} g(f(x))$.

A binary relation $R$ on $A$ and $B$ is functional if it satisfies
\[
\fa x \exunique y R(x,y).
\]
In that case, a logician might use "iota notation,"
\[
f(x) = \iota y \; R(x, y)
\]
to define $f(x)$ to be equal to the unique $y$ satsifying $R(x,y)$. If
$R$ satisfies the weaker property 
\[
\fa x \ex y R(x,y),
\]
a logician might use "the Hilbert epsilon" to define a function
\[
f(x) = \varepsilon y \; R(x, y)
\]
to "choose" a value of $y$ satisfying $R(x, y)$. As we have noted
above, this is an implicit use of the axiom of choice.

second-order and higher-order logic.

For example, saying that a function has an inverse or that two sets
are in one-to-one correspondence involves second-order
quantification. (Fill in examples.)

** Functions in Lean

The fact that the notions we have been discussing have such a
straightforward logical form means that it is easy to define them in
Lean. The main difference between the formal representation in Lean
and the informal representation above is that, in Lean, we distinguish
between a type =X= and a subset =A : set X= of that type. 

In Lean's library, composition and identity are defined as follows:
#+BEGIN_SRC lean
variables {A : Type} {B : Type} {C : Type} {D : Type}

definition compose (f : B → C) (g : A → B) : A → C :=
λx, f (g x)

infixr  ` ∘ ` := compose

definition id (a : A) : A :=
a
#+END_SRC
Ordinarily, to use these definitions the notation, you use the command
=open function=. We omit this command here, because we are duplicating
the definitions, for expository purposes.

Ordinarily, we use =funext= (for "function extensionality") to prove
that two functions are equal. 
#+BEGIN_SRC lean
variables {A B : Type}

-- BEGIN
example (f g : A → B) (H : ∀ x, f x = g x) : f = g := 
funext H
-- END
#+END_SRC
But Lean can prove some basic identities by simply unfolding
definitions and simplifying expressions, using reflexivity.

#+BEGIN_SRC lean
variables {A B C D : Type}

definition compose (f : B → C) (g : A → B) : A → C :=
λx, f (g x)

infixr  ` ∘ ` := compose

definition id (a : A) : A :=
a

-- BEGIN
lemma left_id (f : A → B) : id ∘ f = f := rfl

lemma right_id (f : A → B) : f ∘ id = f := rfl

theorem compose.assoc (f : C → D) (g : B → C) (h : A → B) : (f ∘ g) ∘ h = f ∘ (g ∘ h) := rfl

theorem compose.left_id (f : A → B) : id ∘ f = f := rfl

theorem compose.right_id (f : A → B) : f ∘ id = f := rfl
-- END
#+END_SRC

We can define what it means for $f$ to be injective, surjective, or
bijective:

#+BEGIN_SRC lean
variables {A B C : Type}

definition compose (f : B → C) (g : A → B) : A → C :=
λx, f (g x)

infixr  ` ∘ ` := compose

definition id (a : A) : A :=
a

-- BEGIN
definition injective (f : A → B) : Prop := ∀ ⦃a₁ a₂⦄, f a₁ = f a₂ → a₁ = a₂

definition surjective (f : A → B) : Prop := ∀ b, ∃ a, f a = b

definition bijective (f : A → B) := injective f ∧ surjective f
-- END
#+END_SRC
Marking the variables =a₁= and =a₂= implicit in the definitionof
=injective= means that we do not have to write them as
often. Specifically, given =H : injective f=, and =H₁ a₁ : f a₁ = f
a₂=, we write =H H₁= rather than =H a₁ a₂ H₁= to show =a₁ = a₂=.

We can then prove that the identity function is bijective:
#+BEGIN_SRC lean
variables {A B C : Type}

definition compose (f : B → C) (g : A → B) : A → C :=
λx, f (g x)

infixr  ` ∘ ` := compose

definition id (a : A) : A :=
a

definition injective (f : A → B) : Prop := ∀ ⦃a₁ a₂⦄, f a₁ = f a₂ → a₁ = a₂

definition surjective (f : A → B) : Prop := ∀ b, ∃ a, f a = b

definition bijective (f : A → B) := injective f ∧ surjective f

-- BEGIN
theorem injective_id : injective (@id A) := 
take a₁ a₂, 
assume H : id a₁ = id a₂, 
show a₁ = a₂, from H

theorem surjective_id : surjective (@id A) := 
take a, 
show ∃ x, id x = a, from exists.intro a rfl

theorem bijective_id : bijective (@id A) := and.intro injective_id surjective_id
-- END
#+END_SRC
More interestingly, we can prove that the composition of injective
functions is injective, and so on.
#+BEGIN_SRC lean
variables {A B C : Type}

definition compose (f : B → C) (g : A → B) : A → C :=
λx, f (g x)

infixr  ` ∘ ` := compose

definition id (a : A) : A :=
a

definition injective (f : A → B) : Prop := ∀ ⦃a₁ a₂⦄, f a₁ = f a₂ → a₁ = a₂

definition surjective (f : A → B) : Prop := ∀ b, ∃ a, f a = b

definition bijective (f : A → B) := injective f ∧ surjective f

-- BEGIN
theorem injective_compose {g : B → C} {f : A → B} (Hg : injective g) (Hf : injective f) :
  injective (g ∘ f) :=
take a₁ a₂, 
suppose (g ∘ f) a₁ = (g ∘ f) a₂, 
have f a₁ = f a₂, from Hg this,
show a₁ = a₂, from Hf this

theorem surjective_compose {g : B → C} {f : A → B} (Hg : surjective g) (Hf : surjective f) :
  surjective (g ∘ f) :=
take c,
obtain b (Hb : g b = c), from Hg c,
obtain a (Ha : f a = b), from Hf b,
have g (f a) = c, from eq.subst (eq.symm Ha) Hb,
show ∃ x, g (f x) = c, from exists.intro a this

theorem bijective_compose {g : B → C} {f : A → B} (Hg : bijective g) (Hf : bijective f) :
  bijective (g ∘ f) :=
obtain Hginj Hgsurj, from Hg,
obtain Hfinj Hfsurj, from Hf,
and.intro (injective_compose Hginj Hfinj) (surjective_compose Hgsurj Hfsurj)
-- END
#+END_SRC

The notions of left and right inverse are defined in the expected way.
#+BEGIN_SRC lean
variables {A B : Type}

-- BEGIN
-- g is a left inverse to f
definition left_inverse (g : B → A) (f : A → B) : Prop := ∀x, g (f x) = x

-- g is a right inverse to f
definition right_inverse (g : B → A) (f : A → B) : Prop := left_inverse f g
-- END
#+END_SRC
In particular, composing with a left or right inverse yields the
identity.
#+BEGIN_SRC lean
variables {A B C : Type}

definition compose (f : B → C) (g : A → B) : A → C :=
λx, f (g x)

infixr  ` ∘ ` := compose

definition id (a : A) : A :=
a

definition left_inverse (g : B → A) (f : A → B) : Prop := ∀x, g (f x) = x

definition right_inverse (g : B → A) (f : A → B) : Prop := left_inverse f g

-- BEGIN
definition id_of_left_inverse {g : B → A} {f : A → B} : left_inverse g f → g ∘ f = id :=
assume H, funext H

definition id_of_right_inverse {g : B → A} {f : A → B} : right_inverse g f → f ∘ g = id :=
assume H, funext H
-- END
#+END_SRC
Notice that we need to use =funext= to show the equality of functions.

The following hsows that if a function has a left inverse, then it is
injective, and it it has a right inverse, then it is surjective.
#+BEGIN_SRC lean
variables {A B : Type}

definition injective (f : A → B) : Prop := ∀ ⦃a₁ a₂⦄, f a₁ = f a₂ → a₁ = a₂

definition surjective (f : A → B) : Prop := ∀ b, ∃ a, f a = b

definition left_inverse (g : B → A) (f : A → B) : Prop := ∀x, g (f x) = x

definition right_inverse (g : B → A) (f : A → B) : Prop := left_inverse f g

-- BEGIN
theorem injective_of_left_inverse {g : B → A} {f : A → B} : left_inverse g f → injective f :=
assume h, take a b, assume faeqfb,
calc a = g (f a) : by rewrite h
   ... = g (f b) : faeqfb
   ... = b       : by rewrite h

theorem surjective_of_right_inverse {g : B → A} {f : A → B} : right_inverse g f → surjective f :=
assume h, take b,
let  a : A := g b in
have f a = b, from calc
  f a  = (f (g b))    : rfl
   ... = b            : h b
   ... = b            : rfl,
show ∃ x, f x = b, from exists.intro a this
-- END
#+END_SRC

[Show how inverses are defined.]

** Functions and Sets in Lean

mapsto, inj-on, etc.

image.


# exercises

# composition of relations

# inverse relation
