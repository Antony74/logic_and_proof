#+Title: Logic and Proof
#+Author: [[http://www.andrew.cmu.edu/user/avigad][Jeremy Avigad]], [[http://www.andrew.cmu.edu/user/rlewis1/][Robert Y. Lewis]],  [[http://www.contrib.andrew.cmu.edu/~fpv/][Floris van Doorn]]

* Truth Tables and Semantics
:PROPERTIES:
  :CUSTOM_ID: Truth_Tables_and_Semantics
:END:

In the last chapter, we saw how to prove a formula of propositional
logic from hypotheses. Some formulas are provable outright, from no
hypotheses at all, such as the formula $A \to A$.

It seems intuitively clear that, in contrast, we cannot prove the
formula $A \to B$ without additional assumptions. Try it in Lean:
#+BEGIN_SRC lean
variables A B : Prop

example : A → B :=
assume H : A,
show B, from sorry
#+END_SRC
It should seem unlikely that there is an argument we could put in
place of the "sorry" to complete this proof. After all, =B= could be
false!

What do we mean by "false," exactly? We used the identifiers =true=
and =false= to denote certain propositions in Lean, but here we are
using the words in a difference sense, as values, or judgments, we
can assign to propositional formulas. Such evaluations belong to the
realm of /semantics/. Formulas and formal proofs are /syntactic/
notions, which is to say, they are represented by symbols and symbolic
structures. Truth is a /semantic/ notion, in that it ascribes a type
of /meaning/ to certain formulas.

Syntactically, we were able to ask and answer questions like the
following:
- Given a set of hypotheses, $\Gamma$, and a formula, $A$, can we
  derive $A$ from $\Gamma$?
- What formulas can be derived from $\Gamma$?
- What hypotheses are need to derive $A$?

The questions we consider semantically are different:
- Given an assignment of truth values to the propositional
  variables occurring in a formula $A$, is $A$ true or false?
- Is there any truth assignment that makes $A$ true?
- Which are the truth assignments that make $A$ true?

These syntactic and semantic notions complement each other, in ways we
will describe below. But first, we will discuss methods we can use to
answer semantic questions like the ones above.

** Truth values and assignments

The first notion we will need is that of a /truth value/. We have
already seen two, namely, "true" and "false." We will use the symbols
$\true$ and $\false$ in informal mathematics. These are the values
that $\top$ and $\bot$ are intended to denote in natural deduction,
and =true= and =false= are intended to denote in Lean.

In this text, we will adopt a "classical" notion of truth, following
our discussion in Section [[file:02_Propositional_Logic.org::#Classical_Reasoning][Classical Reasoning]]. This can be understood
in various ways, but, concretely, it comes down to this: we will
assume that any proposition is either true or false, but not
both. This conception of truth is what underlies the law of the
excluded middle, $A \vee \neg A$. Semantically, we read this sentence
as saying "either $A$ is true, or $\neg A$ is true." Since, in our
semantic interpretation, $\neg A$ is true exactly when $A$ is false,
the law of the excluded middle says that $A$ is either true or false.

The next notion we will need is that of a /truth assignment/, which is
simply a function that assigns a truth value to each element of a
propositional variables. For example, the function $v$ defined by
 
- $v(A) := \true$
- $v(B) := \false$
- $v(C) := \false$
- $v(D) := \true$

is a truth assignment for the set of variables $\{ A, B, C, D \}$. 

Intuitively, a truth assignment describes a possible "state of the
world." Going back to the Malice and Alice puzzle, let's suppose the
following letters are shorthand for the statements:

- $P$ := Alice's brother was the victim
- $Q$ := Alice was the killer
- $R$ := Alice was in the bar

In the world described by the solution to the puzzle, the first and
third statements are true, and the second is false. So our truth
assignment gives the value $\true$ to $P$ and $R$, and the value
$\false$ to $Q$.

** Evaluating Formulas

Once we have a truth assignment $v$ to a set of propositional
variables, we can extend it to a /valuation function/ $\bar v$, which
assigns a value of true or false to every propositional formula that
depends only on these variables. The function $\bar v$ is defined
recursively, which is to say, formulas are evaluated from the bottom
up, so that value assigned to a compound formula is determined by the
values assigned to its components. Formally, the function is defined
as follows:
- $\bar v(\top) = \true$
- $\bar v(\bot) = \false$
- $\bar v(\ell) = v(\ell)$, where $\ell$ is any propositional variable.
- $\bar v(\neg \varphi) = \true$ if $\bar v(\varphi)$ is $\false$, and vice
  versa.
- $\bar v(\varphi \wedge \psi) = \true$ if $\bar v(\varphi)$ and $\bar
  v(\psi)$ are both $\true$, and $\false$ otherwise.
- $\bar v(\varphi \vee \psi) = \true$ if at least one of $\bar v(\varphi)$ and
  $\bar v(\psi)$ is $\true$; otherwise $\false$.
- $\bar v(\varphi \to \psi) = \true$ if either $\bar v(\psi)$ is $\true$ or
  $\bar v(\varphi)$ is $\false$, and $\false$ otherwise. (Equivalently,
  $\bar v(\varphi \to \psi) = \false$ if $\bar v(\varphi)$ is $\true$ and
  $\bar v(\psi)$ is $\false$, and $\true$ otherwise.)
  
The rules for conjunction and disjunction are easy to understand. "A
and B" is true exactly when A and B are both true; "A or B" is true when
at least one of A or B is true.

Understanding the rule for implication is trickier. People are often
surprised to hear that any if-then statement with a false hypothesis
is supposed to be true. The statement "if I have two heads, then
circles are squares" may sound like it ought to be false, but by our
reckoning, it comes out true. To make sense of this, think about the
difference between the two sentences:
- "If I have two heads, then circles are squares."
- "If I had two heads, then circles would be squares."
The second sentence is an example of a /counterfactual/
implication. It asserts something about how the world might change, if
things were other than they actually are. Philosophers have studied
counterfactuals for centuries, but mathematical logic is concerned
with the first sentence, a /material/ implication. The material
implication asserts something about the way the world is right now,
rather than the way it might have been. Since it is false that I
have two heads, the statement "if I have two heads, then circles are
squares" is true.

Why do we evaluate material implication in this way? Once again, let
us consider the true sentence "every natural number that is prime and
greater than two is odd." We can interpret this sentence as saying
that all of the (infinitely many) sentences in this list are true:
- if 0 is prime and greater than 2, then 0 is odd
- if 1 is prime and greater than 2, then 1 is odd
- if 2 is prime and greater than 2, then 2 is odd
- if 3 is prime and greater than 2, then 3 is odd
- ...

The first sentence on this list is a lot like our "two heads" example,
since both the hypothesis and the conclusion are false. But since it
is an instance of a statement that is true in general, we are
committed to assigning it the value $\true$.  The second sentence is a
different: the hypothesis is still false, but here the conclusion is
true. Together, these tell us that whenever the hypothesis is false,
the conditional statement should be true. The fourth sentence has a
true hypothesis and a true conclusion. So from the second and fourth
sentences, we see that whenever the conclusion is true, the
conditional should be true as well.  Finally, it seems clear that the
sentence "if 3 is prime and greater than 2, then 3 is even" should
/not/ be true. This pattern, where the hypothesis is true and the
conclusion is false, is the only one for which the conditional will be
false.

Let us motivate the semantics for material implication another way,
using the deductive rules described in the last chapter. Notice that,
if $B$ is true, we can prove $A \to B$ without any assumptions about
$A$.
\begin{prooftree}
\AXM{B}
\UIM{A \to B}
\end{prooftree}
This follows from the proper reading of the implication introduction
rule: given $B$, one can always infer $A \to B$, and then cancel an
assumption $A$, \emph{if there is one}. If $A$ was never used in the
proof, the conclusion is simply weaker than it needs to be. This
inference is validated in Lean:
#+BEGIN_SRC lean
variables A B : Prop
premise HB : B

example : A → B :=
assume HA : A, 
  show B, from HB
#+END_SRC
Similarly, if $A$ is false, we can prove $A \to B$ without any
assumptions about $B$:
\begin{prooftree}
\AXM{\neg A}
\AXM{}
\RLM{H}
\UIM{A}
\BIM{\bot}
\RLM{H}
\UIM{A \to B}
\end{prooftree}
In Lean:
#+BEGIN_SRC lean
variables A B : Prop
premise HnA : ¬ A

example : A → B :=
assume HA : A, 
  show B, from false.elim (HnA HA)
#+END_SRC

Finally, if $A$ is true and $B$ is false, we can prove $\neg (A
\to B)$:
\begin{prooftree}
\AXM{\neg B}
\AXM{}
\RLM{H}
\UIM{A \to B}
\AXM{A}
\BIM{B}
\BIM{\bot}
\RLM{H}
\UIM{\neg (A \to B)}
\end{prooftree}
Once again, in Lean:
#+BEGIN_SRC lean
variables A B : Prop
premise HA : A
premise HnB : ¬B

example : ¬ (A → B) :=
assume H : A → B,
have HB : B, from H HA,
show false, from HnB HB
#+END_SRC

** Finding truth assignments

Now that we have defined the truth of any formula relative to a truth
assignment, we can answer our first semantic question: given an
assignment $v$ of truth values to the propositional variables occurring
in some formula $\ph$, how do we determine whether or not $\ph$ is
true?  This amounts to evaluating $\bar v(\ph)$, and the recursive
definition of $\ph$ gives a recipe: we evaluate the expressions
occurring in $\ph$ from the bottom up, starting with the propositional
variables, and using the evaluation of an expression's components to
evaluate the expression itself. For example, suppose our truth
assignment $v$ makes $A$ and $B$ true and $C$ false. To evaluate $(B
\to C) \vee (A \wedge B)$ under $v$, note that the expression $B \to
C$ comes out false and the expression $A \wedge B$ comes out
true. Since a disjunction "false or true" is true, the entire formula
is true.

We can also go in the other direction: given a formula, we can attempt
to find a truth assignment that will make it true (or false). In fact,
we can use Lean to evaluate formulas for us. In the example that
follows, you can assign any set of values to the proposition symbols
=A=, =B=, =C=, =D=, and =E=. When you run Lean on this input, the
output of the =eval= statement is the value of the expression.
#+BEGIN_SRC lean
-- Define your truth assignment here, by changing the true/false values as you wish.
definition A : Prop := true
definition B : Prop := false
definition C : Prop := true
definition D : Prop := true
definition E : Prop := false

-- Ignore this line.
attribute A B C D E [reducible] 

eval is_true ((A ∧ B) ∨ C)
eval is_true (A → D)
eval is_true (C → (D ∨ ¬E))
eval is_true (¬(A ∧ B ∧ C ∧ D))
#+END_SRC
Try varying the truth assignments, to see what happens. You can add
your own formulas to the end of the input, and evaluate them as
well. Try to find truth assignments that make each of the formulas
tested above evaluate to true. For an extra challenge, try finding a single
truth assignment that makes them all true at the same time.

*** Truth tables

The second and third semantic questions we asked are a little trickier
than the first.  Instead of considering one particular truth
assignment, they ask us to quantify over /all/ possible truth
assignments.

Of course, the number of possible truth assignments depends on the
number of propositional letters we're considering. Since each letter
has two possible values, $n$ letters will produce $2^n$ possible truth
assignments. This number grows very quickly, so we'll mostly look at
smaller formulas here.

We'll use something called a /truth table/ to figure out when, if
ever, a formula is true.  On the left hand side of the truth table,
we'll put all of the possible truth assignments for the present
propositional letters. On the right hand side, we'll put the truth
value of the entire formula under the corresponding assignment.

To begin with, truth tables can be used to concisely summarize the
semantics of our logical connectives:
\begin{center}
\begin{tabular} {|c|c||c|}
\hline
$A$      & $B$      & $A \wedge B$ \\ \hline
$\true$  & $\true$  & $\true$      \\ \hline
$\true$  & $\false$ & $\false$     \\ \hline
$\false$ & $\true$  & $\false$     \\ \hline
$\false$ & $\false$ & $\false$     \\ \hline
\end{tabular}
\quad
\begin{tabular} {|c|c||c|}
\hline
$A$      & $B$      & $A \vee B$ \\ \hline
$\true$  & $\true$  & $\true$      \\ \hline
$\true$  & $\false$ & $\true$      \\ \hline
$\false$ & $\true$  & $\true$      \\ \hline
$\false$ & $\false$ & $\false$     \\ \hline
\end{tabular}
\quad
\begin{tabular} {|c|c||c|}
\hline
$A$      & $B$      & $A \to B$ \\ \hline
$\true$  & $\true$  & $\true$      \\ \hline
$\true$  & $\false$ & $\false$     \\ \hline
$\false$ & $\true$  & $\true$      \\ \hline
$\false$ & $\false$ & $\true$      \\ \hline
\end{tabular}
\end{center}
We will leave it to you to write the table for $\neg A$, as an easy
exercise.

For compound formulas, the style is much the same. Sometimes it can be
helpful to include intermediate columns with the truth values of
subformulas:
\begin{center}
 \begin{tabular} {|c|c|c||c|c||c|}
\hline 
$A$      & $B$      & $C$      & $A \to B$ & $B \to C$ & $(A \to B) \vee (B \to C)$ \\ \hline
$\true$  & $\true$  & $\true$  & $\true$   & $\true$   & $\true$   \\ \hline
$\true$  & $\true$  & $\false$ & $\true$   & $\false$  & $\true$   \\ \hline
$\true$  & $\false$ & $\true$  & $\false$  & $\true$   & $\true$   \\ \hline
$\true$  & $\false$ & $\false$ & $\false$  & $\true$   & $\true$   \\ \hline
$\false$ & $\true$  & $\true$  & $\true$   & $\true$   & $\true$   \\ \hline
$\false$ & $\true$  & $\false$ & $\true$   & $\false$  & $\true$   \\ \hline
$\false$ & $\false$ & $\true$  & $\true$   & $\true$   & $\true$   \\ \hline
$\false$ & $\false$ & $\false$ & $\true$   & $\true$   & $\true$   \\ \hline
\end{tabular}
\end{center}
By writing out the truth table for a formula, we can glance at the
rows and see which truth assignments make the formula true. If all the
entries in the final column are $\true$, as in the above example, the
formula is said to be /valid/.

We can use Lean to check if whether we have evaluated a formula
correctly:
#+BEGIN_SRC lean
/-                   Put your formula here  -/
/-                   \/                     -/
eval let e :=
  λ A      B,        A ∧ (B → A)   in is_true (
( e true   true   ↔  true          ) ∧
( e true   false  ↔  true          ) ∧
( e false  true   ↔  false         ) ∧
( e false  false  ↔  false         ) )
#+END_SRC
You can replace the formula =A ∧ (B → A)= with any other formula
involving the variables =A= and =B=. Then, leaving the first two
columns alone, modify the third column by entering the value =true= or
=false= corresponding to the assignment in the first two columns. The
resulting expression will evaluate to true if and only if you have
entered the correct truth values.

(The precise mechanism by which this works is not important right now,
but in case you are curious, the idea is as follows. In the
expression, the =e= is "locally" defined to be the function which
takes two truth values =A= and =B= as input, and evaluates =A ∧ (B →
A)= relative to these inputs. For each line in the truth table, the
expression checks whether the formula evaluates to the value you
entered, and takes the conjunction of the results.)

# Here is the analogous setup for three variables:
# #+BEGIN_SRC lean
# eval let e :=
#   λ A      B      C,        A ∧ (B → C)   in is_true (
# ( e true   true   true   ↔  true          ) ∧ 
# ( e true   true   false  ↔  false         ) ∧
# ( e true   false  true   ↔  true          ) ∧
# ( e true   false  false  ↔  true          ) ∧
# ( e false  true   true   ↔  false         ) ∧
# ( e false  true   false  ↔  false         ) ∧
# ( e false  false  true   ↔  false         ) ∧
# ( e false  false  false  ↔  false         ) )
# #+END_SRC

** Soundness and Completeness

Fix a deductive system, such as natural deduction. A
propositional formula is said to be /provable/ if there is a formal
proof of it in the system. A propositional formula is said to be a
/tautology/, or /valid/, if it is true under any truth
assignment. Provability is a syntactic notion, insofar as it asserts
the existence of a syntactic object, namely, a proof. Validity is a
semantic notion, insofar as it has to do with truth assignments and
valuations. But, intuitively, these notions should coincide: both
express the idea that a formula $A$ /has/ to be true, or is
/necessarily/ true, and one would expect a good proof system to enable
us to derive the valid formulas.

Because of the way we have chosen our inference rules and defined the
notion of a valuation, this intuition holds true. The statement that
every provable formula is valid is known as /soundness/, and the
statement that we can prove every valid formula is known as
/completeness/.

These notions extend to provability from hypotheses. If $\Gamma$ is a
set of propositional formulas and $A$ is a propositional formula, then
$A$ is said to be a /logical consequence/ of $\Gamma$ if, given any
truth assignment that makes every formula in $\Gamma$ true, $A$ is
true as well. In this extended setting, soundness says that if $A$ is
provable from $\Gamma$, then $A$ is a logical consequence of
$\Gamma$. Completeness runs the other way: if $A$ is a logical
consequence of $\Gamma$, it is provable.

Notice that with the rules of natural deduction, a formula $A$ is
provable from a set of hypotheses $\{ B_1, B_2, \ldots, B_n \}$ if and only
if the formula $B_1 \wedge B_2 \wedge \cdots \wedge B_n \to A$ is
provable outright, that is, from no hypotheses. So, at least for
finite sets of formulas $\Gamma$, the two statements of soundness and
completeness are equivalent.

Proving soundness and completeness belongs to the realm of
/metatheory/, since it requires us to reason about our methods of
reasoning. This is not a central focus of this course: we are more
concerned with /using/ logic and the notion of truth than with
establishing their properties. But the notions of soundness and
completeness play an important role in helping us understand the
nature of the logical notions, and so we will try to provide some
hints here as to why these properties hold for propositional logic.

Proving soundness is easier. We wish to show that whenever $A$ is
provable from a set of hypotheses, $\Gamma$, then $A$ is a logical
consequence of $\Gamma$. In a later chapter, we will consider proofs
by induction, which allows us to establish a property holds of a
general collection of objects by showing that it holds of some
"simple" ones and is preserved under the passage to objects that are
more complex. In the case of natural deduction, it is enough to show
that soundness holds of the most basic proofs --- using the assumption
rule --- and that it is preserved under each rule of inference. The
base case is easy: the assumption rule says that $A$ is provable from
hypothesis $A$, and clearly every truth assignment that makes $A$ true
makes $A$ true. The inductive steps are not much harder; it involves
checking that the rules we have chosen mesh with the semantic
notions. For example, suppose the last rule is the and introduction
rule. In that case, we have a proof of $A$ from some hypotheses
$\Gamma$, and a proof of $B$ from some hypotheses $\Delta$, and we
combine these to form a proof of $A \wedge B$ from the hypotheses in
$\Gamma \cup \Delta$, that is, the hypotheses in both. Inductively, we
can assume that $A$ is a logical consequence of $\Gamma$ and that $B$
is a logical consequence of $\Delta$. Let $v$ be any truth assignment
that makes every formula in $\Gamma \cup \Delta$ true. Then by the
inductive hypothesis, we have that it makes $A$ true, and $B$ true as
well. By the definition of the valuation function, $\bar v (A \wedge
B) = \true$, as required.

Proving completeness is harder. It suffices to show that if $A$ is any
tautology, then $A$ is provable. One strategy is to show that natural
deduction can simulate the method of truth tables. For example,
suppose $A$ is build up from propositional variables $B$ and $C$. Then
in natural deduction, we should be able to prove 

\begin{equation*}
(B \wedge C) \vee (B \wedge \neg C) \vee (\neg B \wedge C) \vee
(\neg B \wedge \neg C),
\end{equation*}

with one disjunct for each line of the truth table. Then, we should
be able to use each disjunct to "evaluate" each expression occurring
in $A$, proving it true or false in accordance with its valuation,
until we have a proof of $A$ itself.

A nicer way to proceed is to express the rules of natural deduction
in a way that allows us to work backwards from $A$ in search of a
proof. In other words, first, we give a procedure for constructing a
derivation of $A$ by working backwards from $A$. Then we argue that if
the procedure fails, then, at the point where it fails, we can find a
truth assignment that makes $A$ false. As a result, if every truth
assignment makes $A$ true, the procedure returns a proof of $A$.

# JA : I think the proof below is more detail than we can / want
# students to see at this stage.

# To show that our proof system is sound, suppose that we have a proof
# of some formula $\varphi$ with no hypotheses. We proceed by induction
# on the length of this proof.

# If the proof has only one inference step, this step must be truth
# introduction, and $\varphi$ must be $\top$. This is because truth
# introduction is our only inference rule that has no hypotheses. Since
# $\top$ always evaluates to true, we are done.

# Now, suppose that any statement we can prove with fewer than $n$
# inference steps must be true, and suppose our proof of $\varphi$ has
# exactly $n$ steps. We examine the final step of the proof.

# - If this final step is $\top$ I, then again, $\varphi$
#   must be $\top$ which evaluates to true.
# - If this final step is $\bot$ E, then we must have a proof of
#   $\bot$ using $n-1$ steps. But by our induction hypothesis, this means
#   that $\bot$ must be true, which cannot be. So the final step cannot
#   be false elimination.
# - If the final step is $\to$ I, then $\varphi$ has the form 
#   $\varphi_1 \to \varphi_2$ and we have a proof in $n-1$ steps
#   that $\varphi_2$ follows from the hypothesis $\varphi_1$. This means
#   that any truth assignment making the hypothesis $\varphi_1$ true must
#   make $\varphi_2$ true as well. And this is exactly the condition
#   under which $\varphi_1 \to \varphi_2$ evaluates to true.
# - Since $\neg$ I is an instance of $\to$ I when $\neg \psi$ is defined to be
#   $\psi \to \bot$, this case is subsumed by the previous.
# - If the final step if $\to$ E, then we have some $psi$ and proofs 
#   of $\psi \to \varphi$ and $\psi$ totaling $n-1$ steps. Thus by our
#   induction hypothesis, $\psi$ and $\psi \to \varphi$ must be valid;
#   if $\psi$ is always true, and $\psi \to \varphi$ is always true,
#   then $\varphi$ must always be true as well.
# - If the final step is $\neg$ E, then we have a proof in $n-1$ steps that
#   $\bot$ follows from the hypothesis $\neg \varphi$. So, any truth
#   assignment that makes $\neg \varphi$ true will make $\bot$ true.
#   But since $\bot$ will never be true, $\neg \varphi$ will never be true,
#   so equivalently $\varphi$ can never be false.
# - If the final step is $\vee$ I, then $\varphi$ has the form
#   $\varphi_1 \vee \varphi_2$, and we have a proof of one of these in $n-1$
#   steps. Suppose for simplicity it's $\varphi_1$. Then $\varphi_1$ must
#   be true, by the induction hypothesis, and $\varphi_1 \vee \varphi_2$
#   must be true by the semantics of $\vee$.
# - If the final step is $\vee$ E, then we have proofs of three formulas
#   totaling $n-1$ steps: $\psi_1 \vee \psi_2$, $\psi_1 \to \varphi$,
#   and $\psi_2 \to \varphi$. Since the disjunction is true, at least one
#   of the disjuncts must be true, and combining this disjunct with 
#   the appropriate one of the two implications shows us that $\varphi$
#   is true as well.
# - Finally, $\wedge$ I and $\wedge$ E are the simplest of the cases.
#   We leave these as an exercise for you!

# What have we shown? We've shown that when we have a proof of $\varphi$
# from no assumptions, no matter what that proof looks like, $\varphi$
# must be true under all truth assignments. So we cannot prove anything
# that is not valid: this is /soundness/.

# If you were asked to show that a formula is provable, you'd know
# how to do it: you'd find a proof of that formula. Arguing that a formula
# is /not/ provable seems trickier, but our soundness theorem helps us our
# here! If we can find a truth assignment that makes a formula false,
# then that formula is not valid, and hence we cannot prove it. By this
# reasoning, it's impossible to prove $A \to B$ without any extra assumptions.

# CONTINUE: completeness
