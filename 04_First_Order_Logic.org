#+Title: Logic and Proof
#+Author: [[http://www.andrew.cmu.edu/user/avigad][Jeremy Avigad]], [[https://www.andrew.cmu.edu/user/rlewis1/][Robert Y. Lewis]],  [[http://www.contrib.andrew.cmu.edu/~fpv/][Floris van Doorn]]

* First Order Logic

Propositional logic provides a good start at describing the general
principles of logical reasoning, but it does not go far enough. Some
of the limitations are apparent even in the "Malice and Alice" example
from Chapter [[file:02_Propositional_Logic.org::#Propositional_Logic][Propositional Logic]]. Propositional logic does not give us
the means to express a general principle that tells us that if Alice
is with her son on the beach, then her son is with Alice; the general
fact that no child is younger than his or her parent; or the general
fact that if someone is alone, they are not with someone else. To
express principles like these, we need a way to talk about objects and
individuals, as well as their properties and the relationships between
them. These are exactly what is provided by a more expressive logical
framework known as /first-order logic/, which will be the topic of
the next few chapters.

** Functions, Relations, and Predicates

Consider some ordinary statements about the natural numbers:
- Every natural number is even or odd, but not both.
- A natural number is even if and only if it is divisible by two.
- If some natural number, $x$, is even, then so is $x^2$.
- A natural number $x$ is even if and only if $x + 1$ is odd.
- For any three natural numbers $x$, $y$, and $z$, is $x$ divides $y$
  and $y$ divides $z$, then $x$ divides $z$.
These statements are true, but we generally do not think of them as
/logically/ valid: they depend on assumptions about the natural
numbers, the meaning of the terms "even" and "odd," and so on. But
once we accept the first statement, for example, it seems to be a
logical consequence that the number of stairs in the White House is
either even or odd, and, in particular, if it is not even, it is
odd. To make sense of inferences like these, we need a logical system
that can deal with objects, their properties, and relations between
them.

Rather than fix a single language once and for all, first-order logic
allows us to specify the symbols we wish to use for any given domain
of interest. In this section, we will use the following running
example:
- the domain of interest is the natural numbers, $\mathbb{N}$.
- there are objects, $1$, $2$, $3$, ....
- there are functions, addition and multiplication, as well as the
  square function, on this domain.
- there are predicates on this domain, "even," "odd," and "prime."
- there are relations between elements of this domain, "equal," "less
  than", and "divides."
For our logical language, we will choose symbols 1, 2, 3,
$\fn{add}$, $\fn{mul}$, $\fn{square}$, $\fn{even}$, $\fn{odd}$, $\fn{prime}$,
$\fn{lt}$, and so on, to denote these things. We will also have
variables $x$, $y$, and $z$ ranging over the natural numbers. Note all
of the following.
- Functions can take any number of arguments: if $x$ and $y$ are
  natural numbers, it makes sense to write $\fn{mul}(x, y)$ and
  $\fn{square}(x)$. so $\fn{mul}$ takes two arguments, and
  $\fn{square}$ takes only one.
- Predicates and relations can also be understood in these terms. The
  predicates $\fn{even}(x)$ and $\fn{prime}(x)$ take one argument,
  while the binary relations $\fn{divides}(x, y)$ and $\fn{lt}(x,y)$
  take two arguments.
- Functions are different from predicates! A function takes one or
  more arguments, and returns a /value/. A predicate takes one or more
  arguments, and is either true or false. We can think of predicates
  as returning propositions, rather than values.
- In fact, we can think of the constant symbols $1, 2, 3, \ldots$ as
  special sorts of function symbols that take zero
  arguments. Analogously, we can consider the predicates that take
  zero arguments to be the constant logical values, $\top$ and $\bot$.
- In ordinary mathematics, we often use "infix" notation for binary
  functions and relations. For example, we usually write $x \times y$
  or $x \cdot y$ intead of $\fn{mul}(x, y)$, and we write $x < y$
  instead of $\fn{lt}(x, y)$. We will use these conventions when
  writing proofs in natural deduction, and they are supported in Lean
  as well.
- We will treat the equality relation, $x = y$, as a special binary
  relation that is included in every first-order language.

What makes the language of first-order logic powerful is that one can
build complex expressions out of the basic ones. Starting with the
variables and constants, we can use the function symbols to build up
compound expressions like these:
\begin{equation*}
x + y + z, \quad (x + 1) \times y \times y, \quad \fn{square} (x + y \times z)
\end{equation*}
Such expressions are called "terms." Intuitively, they name objects
in the intended domain of discourse.

Now, using the predicates and relation symbols, we can make assertions
about these expressions:
\begin{equation*}
\fn{even}(x + y + z), \quad \fn{prime}((x + 1) \times y \times y), \quad
\square (x + y \times z) = w, \quad x + y < z
\end{equation*}
Even more interestingly, we can use propositional connectives to build
compound expressions like these:
- $\fn{even}(x + y + z) \wedge \fn{prime}((x + 1) \times y \times y)$
- $\neg (\fn{square} (x + y \times z) = w) \vee x + y < z$
- $x < y \wedge \fn{even}(x) \wedge \fn{even}(y) \to x + 1 < y$
The second one, for example, asserts that either $(x + yz)^2$ is not
equal to $w$, or $x + y$ is less than $z$. Remember, these are
expressions in symbolic logic; in ordinary mathematics, we would
express the notions using words like "is even" and "if and only if,"
as we did above. We will use notation like this whenever we are in the
realm of symbolic logic, for example, when we write proofs in natural
deduction. Expressions like these are called /formulas/. In contrast
to terms, which name things, formulas /say things/; in other words, they
make assertions about objects in the domain of discourse.

One can also declare function and relation symbols in Lean. For
example, the symbols we have just discussed could be introduced as
follows:
#+BEGIN_SRC lean
constant mul : ℕ → ℕ → ℕ
constant add : ℕ → ℕ → ℕ
constant square : ℕ → ℕ
constant even : ℕ → Prop
constant odd : ℕ → Prop
constant prime : ℕ → Prop
constant divides : ℕ → ℕ → Prop
constant lt : ℕ → ℕ → Prop
constant zero : ℕ
constant one : ℕ
#+END_SRC
You can enter =ℕ= with =\nat= or =\N=. In Lean, the =check= command
can be used to make sure an expression is well-formed, and determine
what kind of expression it is:
#+BEGIN_SRC lean
constant mul : ℕ → ℕ → ℕ
constant add : ℕ → ℕ → ℕ
constant square : ℕ → ℕ
constant even : ℕ → Prop
constant odd : ℕ → Prop
constant prime : ℕ → Prop
constant divides : ℕ → ℕ → Prop
constant lt : ℕ → ℕ → Prop
constant zero : ℕ
constant one : ℕ

-- BEGIN
variables w x y z : ℕ

check mul x y
check add x y
check square x
check even x
-- END
#+END_SRC
We can even declare infix notation of binary operations and relations:
#+BEGIN_SRC lean
constant mul : ℕ → ℕ → ℕ
constant add : ℕ → ℕ → ℕ
constant square : ℕ → ℕ
constant even : ℕ → Prop
constant odd : ℕ → Prop
constant prime : ℕ → Prop
constant divides : ℕ → ℕ → Prop
constant lt : ℕ → ℕ → Prop
constant zero : ℕ
constant one : ℕ

variables w x y z : ℕ

check mul x y
check add x y
check square x
check even x 

-- BEGIN
infix + := add
infix * := mul
infix < := lt
-- END
#+END_SRC
(Getting notation for numerals =1=, =2=, =3=, ... is trickier.) With
all this in place, the examples above can be rendered as follows:
#+BEGIN_SRC lean
constant mul : ℕ → ℕ → ℕ
constant add : ℕ → ℕ → ℕ
constant square : ℕ → ℕ
constant even : ℕ → Prop
constant odd : ℕ → Prop
constant prime : ℕ → Prop
constant divides : ℕ → ℕ → Prop
constant lt : ℕ → ℕ → Prop
constant zero : ℕ
constant one : ℕ

variables w x y z : ℕ

check mul x y
check add x y
check square x
check even x 

infix + := add
infix * := mul
infix < := lt

-- BEGIN
check even (x + y + z) ∧ prime ((x + one) * y * y)
check ¬ (square (x + y * z) = w) ∨ x + y < z
check x < y ∧ even x ∧ even y → x + one < y
-- END
#+END_SRC
In fact, all of the functions, predicates, and relations discussed
here, except for the "square" function and "prime," are defined in the
core Lean library. They become available to us when we put the commands
=import data.nat= and =open nat= at the top of a file in Lean.
#+BEGIN_SRC lean
import data.nat
open nat

constant square : ℕ → ℕ
constant prime : ℕ → Prop

variables w x y z : ℕ

check even (x + y + z) ∧ prime ((x + 1) * y * y)
check ¬ (square (x + y * z) = w) ∨ x + y < z
check x < y ∧ even x ∧ even y → x + 1 < y
#+END_SRC
Here, we declare the constants =square= and =prime= axiomatically, but
refer to the other operations and predicates in the Lean library. In
this course, we will often proceed in this way, telling you explicitly
what facts from the library you should use for exercises.

Here are some things to note about the syntax of expression in Lean:
- In contrast to ordinary mathematical notation, in Lean, functions
  are applied without parentheses or commas. For example, we write
  =square x= and =add x y= instead of $\fn{square}(x)$ and
  $\fn{add}(x, y)$.
- The same holds for predicates and relations: we write =even x= and
  =lt x y= instead of $\fn{even}(x)$ and $\fn{lt}(x, y)$, as one might
  do in symbolic logic.
- The notation =add : ℕ → ℕ → ℕ= indicates that addition takes two
  arguments, both natural numbers, and returns a natural number.
- Similarly, the notation =divides : ℕ → ℕ → Prop= indicates that
  =divides= is a binary relation, which takes two natural numbers as
  arguments and forms a proposition. In other words, =divides x y=
  expresses the assertion that =x= divides =y=.

Lean can help us distinguish between terms and formulas. If we =check=
the expression =x + y + 1= in Lean, we are told it has type =ℕ=, which
is to say, it denotes a natural number. If we =check= the expression
=even (x + y + 1)=, we are told that it has type =Prop=, which is to
say, it expresses a proposition.

** Quantifiers 

There are two more ingredients to the language of first-order logic,
namely, the universal and existential quantifiers. The universal
quantifier, $\forall$, followed by a variable $x$ is meant to
represent the phrase "for every $x$." In other words, it asserts that
every value of $x$ has the property in question. Using the universal
quantifier, the examples with which we began this previous section can
be expressed as follows:
\begin{itemize}
\item $\fa x ((\fn{even}(x) \vee \fn{odd}(x)) \wedge \neg
(\fn{even}(x) \wedge \neg \fn{odd}(x)))$.
\item $\fa x (\fn{even}(x) \to \fn{even}(x^2))$
\item $\fa x (\fn{even}(x) \liff 2 \mid x)$
\item $\fa x \fa y \fa z (x \mid y \wedge y \mid z \to x \mid z)$.
\end{itemize}
It is common to combine multiple quantifiers of the same kind, and
write, for example, $\fa {x, y, z} (x \mid y \wedge y \mid z
\to x \mid z)$ in the last expression.

In Lean, you can enter the universal quantifier by writing =\all=. The
same examples are rendered as follows:
#+BEGIN_SRC lean
import data.nat
open nat

variables x y z : ℕ

check ∀ x, (even x ∨ odd x) ∧ ¬ (even x ∧ odd x)
check ∀ x, even x ↔ 2 ∣ x
check ∀ x, even x → even (x^2)
check ∀ x, even x ↔ odd (x + 1)
check ∀ x y z, x ∣ y → y ∣ z → x ∣ z
#+END_SRC
Here are some notes on syntax:
- In symbolic logic, the universal quantifier is usually taken to bind
  tightly. For example, $\fa x P \vee Q$ is interpreted as $(\fa x P)
  \vee Q$, and we would write $\fa x (P \vee Q)$ to extend the scope.
- In contrast, Lean expects a comma after that universal quantifer,
  and gives the it the /widest/ scope possible. For example, =∀ x, P ∨
  Q= is interpreted as =∀ x, (P ∨ Q)=, and we would write =(∀ x, P) ∨
  Q= to limit the scope.
- After the quantifier $\forall x$, the variable $x$ is /bound/. For
  example, the expression $\fa x (\fn{even}(x) \vee \fn{odd}(x))$ is
  expresses that every number is even or odd. Notice that the variable
  $x$ does not appear anywhere in the informal statement. The
  statement is not about $x$ at all; rather $x$ is a dummy variable, a
  placeholder that stands for the "thing" referred to within a phrase
  that beings with the words "every thing." We think of the expression 
  $\fa x (\fn{even}(x) \vee \fn{odd}(x))$ as being the same as the
  expression $\fa y (\fn{even}(y) \vee \fn{odd}(y))$. Lean treats
  these expressions as the same as well.
- The expression =∀ x y z, x ∣ y → y ∣ z → x ∣ z= is interpreted as =∀
  x y z, x ∣ y → (y ∣ z → x ∣ z)=, with parentheses associated to the
  /right/. The part of the expression after the universal quantifier
  can therefore be interpreted as saying "given that =x= divides =y=
  and that =y= divides =z=, =x= divides =z=." The expression is
  logically equivalent to =∀ x y z, x ∣ y ∧ y ∣ z → x ∣ z=, but we
  will see that, in Lean, it is often convenient to express facts like
  this as an iterated implication.

A variable that is not bound is called /free/. Notice that formulas in
first-order logic say things about their free variables. For example,
in the interpretation we have in mind, the formula $\fa y (x \le y)$
says that $x$ is less than or equal to every natural number. The
formula $\fa z (x \le z)$ says exactly the same thing; we can always
rename a bound variable, as long as we pick a name that does not clash
with another name that is already in use. On the other hand, the
formula $\fa y (w \le y)$ says that $w$ is less than or equal to every
natural number. This is an entirely different statement: it says
something about $w$, rather than $x$. In other words, renaming a
/free/ variable changes the meaning of a formula.

Notice also that some formulas, like $\fa {x, y} (x \le y \vee y \le
x)$, have no free variables at all. Such a formula is called a
/sentence/, because it makes an outright assertion, a statement that
is either true or false about the intended interpretation. A couple of
chapters from now, we will make the notion of an "intended
interpetation" precise, and talk about what it means to be "true in an
interpretation." For now, the idea that formulas say things about
about object in an intended interpretation should motivate the rules
for reasoning with such expressions. 

Dual to the universal quantifier is the existential quantifier,
$\exists$, which is used to express assertions such as "some number is
even," or, "between any two even numbers there is an odd number." We
will discuss the existential quantifier and its use in a later
chapter. 

Indeed, to complete the presentation of first-order logic, we need to
present the rules of the universal quantifier, the existential
quantifier, and equality in natural deduction, and in Lean. In this
chapter, we will start with the rules for the universal quantifier,
and provide examples of the kinds of mathematical arguments they are
intended to model.

** Rules for the Universal Quantifier

In the [[file:01_Introduction.org::#Introduction][Introduction]] we proved that the square root of two is
irrational. One way to construe the statement is as follows:
#+BEGIN_QUOTE
For every pair of natural numbers, $a$ and $b$, it is not the case
that $a^2 = 2 b^2$.
#+END_QUOTE
The advantage of this formulation is that we can restrict our
attention to the natural numbers, without having to consider the
larger domain of rationals. In symbolic logic, assuming our intended
domain of discourse is the natural numbers, we woud express this
theorem using the universal quantifier:
\begin{equation*}
\fa {a, b} \neg (a^2 = 2 b^2). 
\end{equation*}
How do we prove such a theorem? Informally, we would use such a
pattern:
#+BEGIN_QUOTE
Let $a$ and $b$ be arbitrary integers, and suppose $a^2 = 2 b^2$.

...

Contradiction.
#+END_QUOTE
What we are really doing is proving that the universal statement
holds, but showing that it holds of "arbitrary" values $a$ and $b$. In
natural deduction, the proof would look something like this:
\begin{prooftree}
\AXM{}
\UIM{H : a^2 = 2 \times b^2}
\UIM{\vdots}
\UIM{\bot}
\RLM{H}
\UIM{\neg (a^2 = 2 \times b^2)}
\UIM{\fa b \neg (a^2 = 2 \times b^2)}
\UIM{\fa a \fa b \neg (a^2 = 2 \times b^2)}
\end{prooftree}
Notice that after the hypothesis $H$ is canceled, we have proved $\neg
(a^2 = 2 \times b^2)$ without making any assumptions about $a$ and
$b$; at this stage in the proof, they are "arbitrary," justifying the
application of the universal quantifiers in the next two rules.

This example motivates the following rule in natural deduction:
\begin{prooftree}
\AXM{A(x)}
\UIM{\fa x A(x)}
\end{prooftree}
provided $x$ is not free in any uncanceled hypothesis. Here $A(x)$
stands for any formula that (potentially) mentions $x$. Also remember
that if $y$ is any "fresh" variable that does not occur in $A$, we are
thinking of $\fa x A(x)$ as being the same as $\fa y A(y)$.

Notice that when we work in first-order logic, we assume that the
universal quantifier ranges over some domain. In Lean, we can declare
a "type" of objects by writing =variable U : Type=. We can then
declare a predicate on =U= by writing =variable P : U → Prop=. In
Lean, then, the pattern for proving a universal statement is rendered
as follows:
#+BEGIN_SRC lean
variable U : Type
variable P : U → Prop

example : ∀ x, P x :=
take x,
show P x, from sorry
#+END_SRC
Read =take x= as "fix and arbitrary value =x= of =U=." Since we are
allowed to rename bound variables at will, we can equivalently write
either of the following:
#+BEGIN_SRC lean
variable U : Type
variable P : U → Prop

example : ∀ y, P y :=
take x,
show P x, from sorry

example : ∀ x, P x :=
take y,
show P y, from sorry
#+END_SRC
This constitutes the introduction rule for the universal quantifier. 

What about the elimination rule? Suppose we know that every number is
even or odd. Then, in an ordinary proof, we are free to assert "$a$ is
even or $a$ is odd," or "$a^2$ is even or $a^2$ is odd." In terms of
symbolic logic, this amounts to the following inference: from $\fa x
(\fn{even}(x) \vee \fn{odd}(x))$, we can conclude $\fn{even}(t) \vee
\fn{odd}(t)$ for any term $t$. This motivates the elimination rule for
the universal quantifier:
\begin{prooftree}
\AXM{\fa x A(x)}
\UIM{A(t)}
\end{prooftree}
where $t$ is an arbitrary term. In a Lean proof, this is implemented
as follows:
#+BEGIN_SRC lean
variable U : Type
variable P : U → Prop
premise H : ∀ x, P x
variable a : U

example : P a :=
show P a, from H a
#+END_SRC
Observe the notation: =P a= is obtained by "applying" the hypothesis
=H= to =a=.

The following example of a proof in natural deduction shows that if,
for every $x$, $A(x)$ holds, and for every $x$, $B(x)$ holds, then for
every $x$, they both hold:
\begin{prooftree}
\AXM{HA : \fa x A(x)}
\UIM{A(y)}
\AXM{HB : \fa x B(x)}
\UIM{B(y)}
\BIM{A(y) \wedge B(y)}
\UIM{\fa y (A(y) \wedge B(y))}
\RLM{HB}
\UIM{\fa x B(x) \to \fa y (A(y) \wedge B(y))}
\RLM{HA}
\UIM{\fa x A(x) \to (\fa x B(x) \to \fa y (A(y) \wedge B(y)))}
\end{prooftree}
Notice that neither of the hypotheses $HA$ or $HB$ mention $y$, so
that $y$ is really "arbitrary" at the point where the universal
quantifiers are introduced.

Here is the same proof rendered in Lean:
#+BEGIN_SRC lean
variable U : Type
variables A B : U → Prop

example : (∀ x, A x) → (∀ x, B x) → (∀ x, A x ∧ B x) :=
assume HA : ∀ x, A x,
assume HB : ∀ x, B x,
take y,
have A y, from HA y,
have B y, from HB y,
show A y ∧ B y, from and.intro `A y` `B y`
#+END_SRC
As an exercise, trying proving $(\fa x (A(x) \wedge B(x))) \to \fa x
A(x)$ in natural deduction or Lean, or
\begin{equation*}
(\fa x (A(x) \to B(x))) \to (\fa x A(x) \to \fa x B(x)).
\end{equation*}
Here is a more challenging exercise. Suppose I tell you that, in a town,
there is a (male) barber that shaves all and only the men who do not
shave themselves. You can show that this is a contradiction, arguing
informally, as follows:
#+BEGIN_QUOTE
By the assumption, the barber shaves himself if and only if he does
not shave himself. Call this statement (*).

Suppose the barber shaves himself. By (*), this implies that he does
not shave himself, a contradiction. So, the barber does not shave
himself.

But using (*) again, this implies that the barber shaves himself,
which contradicts the fact we just showed, namely, that the barber
does not shave himself. 
#+END_QUOTE
Try to turn this into a formal argument in natural deduction, or in
Lean. For the latter, you need only replace each =sorry= below with a
proof:
#+BEGIN_SRC lean
variable Person : Type
variable shaves : Person → Person → Prop
variable barber : Person
premise H : ∀ x, shaves barber x ↔ ¬ shaves x x

example : false :=
have H1 : shaves barber barber ↔ ¬ shaves barber barber, from sorry,
have H2 : ¬ shaves barber barber, from
  assume H2a : shaves barber barber,
  have H2b : ¬ shaves barber barber, from sorry,
  show false, from sorry,
have H3 : shaves barber barber, from sorry,
show false, from sorry
#+END_SRC

** Some Number Theory

Let us return to the example of the natural numbers, to see how
deductive notions play out there. Suppose we have defined $\fn{even}$
and $\fn{odd}$ in such a way that we can prove:
- $\fa n, \neg \even(n) \to \odd(n)$
- $\fa n \odd(n) \to \neg \even(n)$
Then we can go on to derive $\fa n (\even(n) \vee \odd(n))$ as
follows:
\begin{prooftree}
\AXM{}
\UIM{\even(n) \vee \neg \even(n)}
\AXM{}
\UIM{H_1 : \even(n)}
\UIM{\even(n) \vee \odd(n)}
\AXM{}
\UIM{\fa n \neg \even(n) \to \odd(n)}
\UIM{\neg \even (n) \to \odd(n)}
\AXM{}
\UIM{H_2 : \neg \even(n)}
\BIM{\odd(n)}
\UIM{\even(n) \vee \odd(n)}
\RLM{H_1, H_2}
\TIM{\even(n) \vee \odd(n)}
\UIM{\fa n (\even (n) \vee \odd(n)}
\end{prooftree}
We can also prove and $\fa n \neg (\even(n) \wedge \odd(n))$:
\begin{prooftree}
\AXM{}
\UIM{\odd(n) \to \neg \even(n)}
\AXM{}
\UIM{H : \even(n) \wedge \odd(n)}
\UIM{\odd(n)}
\BIM{\neg \even(n)}
\AXM{}
\UIM{H : \even(n) \wedge \odd(n)}
\UIM{\even(n)}
\BIM{\bot}
\RLM{H}
\UIM{\neg (\even(n) \wedge \odd(n))}
\UIM{\fa n \neg (\even(n) \wedge \odd(n))}
\end{prooftree}
As we move from modeling basic rules of inference, however modeling
actual mathematical proofs, we will tend to shift focus from natural
deduction to formal proofs in Lean. Natural deduction has its uses: as
a basic model of logical reasoning, it provides us with a convenient
means to study metatheoretic properties such as soundness and
completeness. For working /within/ the system, however, proof
languages like Lean's tend to scale better, and produce more readable
proofs.

In Lean's library, there are theorems =odd_of_not_even= and
=even_of_not_odd=, whose uses are illustrated in the following:
#+BEGIN_SRC lean
import data.nat
open nat

example : ∀ n, ¬ even n → odd n :=
take n,
assume H : ¬ even n, 
show odd n, from odd_of_not_even H

example : ∀ n, odd n → ¬ even n :=
take n,
assume H : odd n,
show ¬ even n, from not_even_of_odd H
#+END_SRC
Once again, notice the naming scheme: the conlusion is followed by the
hypothesis, separated by the word =of=. Notice also that when applying
the theorems, you do not need to specify the argument =n=: it is
implicit in the hypothesis =H=. We can illustrate these theorems more
concisely, by labeling =n= and =H= in the statement of the example:
#+BEGIN_SRC lean
import data.nat
open nat

-- BEGIN
example (n : ℕ) (H : ¬ even n) : odd n :=
odd_of_not_even H

example (n : ℕ) (H : odd n) : ¬ even n :=
not_even_of_odd H
-- END
#+END_SRC
In this text, we will often present theorems in the library in this
way. Using these two theorems, the two facts we just proved in natural
deduction can be proved in Lean as follows:
#+BEGIN_SRC lean
import data.nat
open nat classical

example : ∀ n, even n ∨ odd n :=
take n,
or.elim (em (even n))
  (suppose even n, 
    show even n ∨ odd n, from or.inl this)
  (suppose ¬ even n,
    have odd n, from odd_of_not_even this,
    show even n ∨ odd n, from or.inr this)

example : ∀ n, ¬ (even n ∧ odd n) :=
take n,
assume H : even n ∧ odd n,
have even n, from and.left H,
have odd n, from and.right H,
have ¬ even n, from not_even_of_odd this,
show false, from `¬ even n` `even n`
#+END_SRC
Notice that we used the command =open classical= in order to use the
law of the excluded middle, =em (even n)=, to split on cases.

Here are some more facts about parity that are found in the Lean
library:
#+BEGIN_SRC lean
import data.nat
open nat

-- BEGIN
example (n : ℕ) (H : even n) : 2 ∣ n :=
dvd_of_even H

example (n : ℕ) (H : 2 ∣ n) : even n :=
even_of_dvd H

example (n : ℕ) : n ∣ n := dvd.refl n

example (k m n : ℕ) (H₁ : k ∣ m) (H₂ : m ∣ n) : k ∣ n :=
dvd.trans H₁ H₂

example (k m n : ℕ) (H₁ : k ∣ m) (H₂ : k ∣ n) : k ∣ m + n :=
dvd_add H₁ H₂

example (k m n : ℕ) (H₁ : k ∣ m + n) (H₂ : k ∣ m) : k ∣ n :=
dvd_of_dvd_add_left H₁ H₂

example (k m n : ℕ) (H₁ : k ∣ m + n) (H₂ : k ∣ n) : k ∣ m :=
dvd_of_dvd_add_right H₁ H₂

example : odd 1 :=
odd_one
-- END
#+END_SRC
To enter the "divides" symbol in Lean, you have to type =\|=. (The
symbol is different from the plain =|= character.) Here are some
examples of theorems that can be proved using these facts:
#+BEGIN_SRC lean
import data.nat
open nat

example : ∀ m n, even m → m ∣ n → even n :=
take m, take n,
suppose even m,
suppose m ∣ n,
have 2 ∣ m, from dvd_of_even `even m`,
have 2 ∣ n, from dvd.trans this `m ∣ n`,
show even n, from even_of_dvd this

example : ∀ m n, even m → even n → even (m + n) :=
take m, take n,
suppose even m,
suppose even n,
have 2 ∣ m, from dvd_of_even `even m`,
have 2 ∣ n, from dvd_of_even `even n`,
have 2 ∣ m + n, from dvd_add `2 ∣ m` `2 ∣ n`,
show even (m + n), from even_of_dvd this

example : ∀ m n, even (m + n) → even m → even n :=
take m, take n,
suppose even (m + n),
suppose even m,
have 2 ∣ m, from dvd_of_even `even m`,
have 2 ∣ (m + n), from dvd_of_even `even (m + n)`,
have 2 ∣ n, from dvd_of_dvd_add_left `2 ∣ m + n` `2 ∣ m`,
show even n, from even_of_dvd this

example : ∀ m n, even (m + n) → even n → even m :=
sorry

example : even 2 :=
have 2 ∣ 2, from dvd.refl 2,
show even 2, from even_of_dvd this
#+END_SRC
The second-to-last one is left to you as an exercise. Remember, when
you are trying to prove such theorems on your own, it is a good idea
to prove them incrementally, using =sorry=. For example, for the first
theorem, you might start as follows:
#+BEGIN_SRC lean
import data.nat
open nat
 
-- BEGIN
example : ∀ m n, even m → m ∣ n → even n :=
take m, take n,
suppose even m,
suppose m ∣ n,
show even n, from sorry
-- END
#+END_SRC
After checking to make sure that Lean accepts this, you can then add
intermediate =have= statements, and so on.

If you wanted to use these theorems later on, you could name them:
#+BEGIN_SRC lean
import data.nat
open nat

theorem even_add_of_even_of_even : ∀ {m n}, even m → even n → even (m + n) :=
take m, take n,
suppose even m,
suppose even n,
have 2 ∣ m, from dvd_of_even `even m`,
have 2 ∣ n, from dvd_of_even `even n`,
have 2 ∣ m + n, from dvd_add `2 ∣ m` `2 ∣ n`,
show even (m + n), from even_of_dvd this

theorem even_of_even_add_left : ∀ {m n}, even (m + n) → even m → even n :=
take m, take n,
suppose even (m + n),
suppose even m,
have 2 ∣ m, from dvd_of_even `even m`,
have 2 ∣ (m + n), from dvd_of_even `even (m + n)`,
have 2 ∣ n, from dvd_of_dvd_add_left `2 ∣ m + n` `2 ∣ m`,
show even n, from even_of_dvd this
#+END_SRC
The curly braces around =m= and =n= in the first two theorems makes
=m= and =n= /implicit arguments/, which means that you can write, for
example, =even_add H₁ H₂= for hypotheses =H₁ : even m= and =H₂ : even
n=, rather than =even_add m n H₁ H₂=. In fact, the first of these is 
already in Lean's library:
#+BEGIN_SRC lean
import data.nat
open nat

check even_add_of_even_of_even
#+END_SRC
Using these, we can go on to prove the following:
#+BEGIN_SRC lean
import data.nat
open nat

theorem even_of_even_add_left : ∀ {m n}, even (m + n) → even m → even n :=
take m, take n,
suppose even (m + n),
suppose even m,
have 2 ∣ m, from dvd_of_even `even m`,
have 2 ∣ (m + n), from dvd_of_even `even (m + n)`,
have 2 ∣ n, from dvd_of_dvd_add_left `2 ∣ m + n` `2 ∣ m`,
show even n, from even_of_dvd this

-- BEGIN
example : ∀ n, even n → odd (n + 1) :=
take n,
suppose even n,
have ¬ even (n + 1), from
  suppose even (n + 1),
  have even 1, from even_of_even_add_left this `even n`,
  have ¬ even 1, from not_even_of_odd odd_one,
  show false, from `¬ even 1` `even 1`,
show odd (n + 1), from odd_of_not_even this

example : ∀ m n, even (m + n) → even n → even m :=
sorry

example : ∀ n, even (n + 1) → odd n :=
sorry
-- END
#+END_SRC
The last two are left for you to do as exercises.

Unfortunately, the facts we have presented to you so far do not let
you prove that if =n= is odd, then =n+1= is even. Fortunately, that
fact is also in the library (=succ= abbreviates "successor"), and you
can use it to prove the second example below.
#+BEGIN_SRC lean
import data.nat
open nat

-- BEGIN
example (n : ℕ) (H : odd n) : even (n + 1) := 
even_succ_of_odd H

example (n : ℕ) (H : odd (n + 1)) : even n :=
sorry
-- END
#+END_SRC

Let us close with some examples of elementary theorems of number
theory. (These are all exercises in Chapter 1 of /An Introduction to
the Theory of Numbers/ by Niven and Zuckerman.) For the moment, we
will loosen up a bit and not insist that every fact we use can be
proved axiomatically; let us take, as "common knowledge," facts such
as these:
- A number is even if and only if it can be expressed in as $2 n$, and
  odd if it can be expressed in the form $2 n + 1$.
- A number is divisible by $k$ if and only if it leaves a remainder of
  0 when you divide it by $k$. In particular, of any $k$ consecutive
  numbers $n, n + 1, n + 2, \ldots, n + (k - 1)$, at least one of them
  will be divisible by $k$.
- Expressed differently, if $k > 0$, then any natural number $n$ can
  be expressed as $n = k q + r$, where $0 \le r < k$.
The last fact is often known as the "quotient-remainder" theorem.

-----
*Theorem.* The product of any three consecutive integers is divisible
by 6.

*Proof.* Denote the three integers by $n$, $n + 1$, and $n + 2$. Then
either $n$ or $n + 1$ is divisible by 2, and either $n$, $n + 1$, or
$n + 2$ is divisible by 3. So, their product is divisible by 6.

*Theorem*. For every $n$, $n^3 - n$ is divisible by 6.

*Proof.* We have $n^3 - n = (n - 1) n (n + 1)$, which is a product of
 three consecutive integers.
-----

As exercises, try writing proving the following, informally:
- For any integer $n$, $n^2$ leaves a remainder of 0 or 1
  when you divide it by 4. Hence $n^2 + 2$ is never divisible by 4.
- If $n$ is odd, $n^2 - 1$ is divisible by 8.
- If $m$ and $n$ are odd, then $m^2 + n^2$ is even but not divisible
  by 4.
- Say that two integers "have the same parity" if they are both even
  or both odd. Prove that if $m$ and $n$ are any two integers, then
  $m + n$ and $m - n$ have the same parity.

** Relativization and Sorts

In first-order logic as we have presented it, there is one intended
"universe" of objects of discourse, and the universal and existential
quantifiers range over that universe. For example, we could design a
language to talk about people living in a certain town, with a
relation $\fn{loves}(x, y)$ to express that $x$ loves $y$. In such a
language, we might express the statement that "everyone loves someone"
by writing $\fa x \ex y \fn{loves}(x, y)$.

You should keep in mind that, at this stage, $\fn{loves}$ is just a
symbol. We have designed the language with a certain interpretation in
mind, but one could also interpret the language as making statements
about the natural numbers, where $\fn{loves}(x, y)$ means that $x$ is
less than or equal to $y$. In that interpretation, the sentence
\begin{equation*}
\fa {x, y, z} (\fn{loves}(x, y) \wedge \fn{loves}(y, z) \to
\fn{loves}(x, z))
\end{equation*}
is true, though in the original interpretation it makes an implausible
claim about the nature of love triangles. In a later chapter, we will
spell out the notion that the deductive rules of first-order logic
enable us to determine the statements that are true in \emph{all}
interpretations, just as the rules of propositional logic enable us to
determine the statements that are true under all truth assignments.

Returning to the original example, suppose we want to represent the
statement that, in our town, all the women are strong and all the men
are good looking. We could do that with the following two sentences:
- $\fa x (\fn{woman}(x) \to \fn{strong}(x))$
- $\fa x (\fn{man}(x) \to \fn{good\mathord{-}looking}(x))$
These are instances of /relativization/. The universal quantifier
ranges over all the people in the town, but this device gives us a way
of using implication to restrict the scope of our statements to men
and women, respectively. The trick also comes into play when we render
"every prime number greater than two is odd":
\begin{equation*}
\fa x (\fn{prime}(x) \wedge x \ge 2 \to \fn{odd}(x)).
\end{equation*}
We could also read this more literally as saying "for every number
$x$, if $x$ is prime and $x$ is greater than or equal to 2, then $x$
is odd," but it is natural to read it as a restricted quantifier. It
is also possible to relativize the existential quantifier to say
things like "some woman is strong" and "some man is good-looking." We
will see how to do this in a later chapter.

Now, suppose we are studying geometry, and we want to express the fact
that given any two distinct points $p$ and $q$ and any two lines $L$
and $M$, if $L$ and $M$ both pass through $p$ and $q$, then they have
to be the same. (In other words, there is at most one line between two
distinct points.) One option is to design a first-order logic where the
intended universe is big enough to include both points and lines, and
use relativization:
\begin{multline*}
\fa {p, q, L, M} (\fn{point}(p) \wedge \fn{point}(q) \wedge
\fn{line}(L) \wedge \fn{line}(M) \\
\wedge \fn{on}(p,L) \wedge \fn{on}(q,L) \wedge \fn{on}(p,M) \wedge
\fn{on}(q,M) \to L = M)
\end{multline*}
But dealing with such predicates is tedious, and there is a mild
extension of first-order logic, called /many-sorted first-order
logic/, which builds in some of the bookkeeping. In many-sorted logic,
one can have different sorts of objects --- such as points and lines
--- and a separate stock of variables and quantifiers ranging over
each. Moreover, the specification of function symbols and predicate
symbols indicates what sorts of arguments they expect, and, in the
case of function symbols, what sort of argument they return. For
example, we might choose to have a sort with variables $p, q, r,
\ldots$ ranging over points, a sort with variables $L, M, N, \ldots$
ranging over lines, and a relation $\fn{on}(p, L)$ relating the
two. Then the assertion above is rendered more simply as follows:
\begin{equation*}
\fa {p, q, L, M} (\fn{on}(p,L) \wedge \fn{on}(q,L) \wedge \fn{on}(p,M) \wedge
\fn{on}(q,M) \to L = M)
\end{equation*}

In Lean, we can model many-sorted logic by introducing a new type
for each sort:
#+BEGIN_SRC lean
variables Point Line : Type
variable  on : Point → Line → Prop

check ∀ (p q : Point) (L M : Line),
        on p L → on q L → on p M → on q M → L = M
#+END_SRC
Notice that we have followed the convention of using iterated
implication rather than conjunction in the antecedent. In fact, Lean
is smart enough to infer what sorts of objects =p=, =q=, =L=, and =M= 
are from the fact that they are used with the relation =on=, so we
could have written more simply this:
#+BEGIN_SRC lean
variables Point Line : Type
variable  on : Point → Line → Prop

-- BEGIN
check ∀ p q L M,
        on p L → on q L → on p M → on q M → L = M
-- END
#+END_SRC

** Elementary Set Theory

In a publication in the journal /Mathematische Annalen/ in 1895, the
German mathematician Georg Cantor presented the following
characterization of the notion of a "set" (or /Menge/, in his
terminology):
#+BEGIN_QUOTE
By a /set/ we mean any collection M of determinate, distinct objects
(called the /elements/ of M) of our intuition or thought into a whole.
#+END_QUOTE
Since then, the notion of a set has been used to unify a wide range of
abstractions and constructions. Axiomatic set theory, which we will
discuss in a later chapter, provides a foundation for mathematics in
which everything can be viewed as a set.

On a broad construal, /any/ collection can be a set; for example, we
can consider the set whose elements are Ringo Star, the number 7, and
the set whose only member is the Empire State Building. With such a
broad notion of set we have to be careful: Russell's paradox has us
consider the set $S$ of all sets that are not elements of themselves,
which leads to a contradiction when we ask whether $S$ is an element
of itself. (Try it!) The axioms of set theory tell us what sets exist,
and have been carefully designed to avoid paradoxical sets like that
of the Russell paradox.

In practice, mathematicians are not so freewheeling in their use of
sets. Typically, one fixes a domain such as the natural numbers, and
consider subsets of that domain. In other words, we consider sets of
numbers, sets of points, sets of lines, and so on, rather than
arbitrary "sets." In this text, we will adopt this convention: when we
talk about sets, we are always implicitly talking about sets of
elements of some domain.

Cantor's characterization suggests that whenever we have some
property, $P$, of a domain, we can form the set of elements that have
that property. This is denoted using "set-builder notation" as $\{ x
\; | \; P(x) \}$. For example, we can consider all the following sets
of natural numbers:
- \( \{n \st \mbox{$n$ is even} \} \)
- \( \{n \st \mbox{$n$ is prime} \} \)
- \( \{n \st \mbox{$n$ is prime and greater than 2} \} \)
- \( \{n \st \mbox{$n$ can be written as a sum of squares} \} \)
- \( \{n \st \mbox{$n$ is equal to 1, 2, or 3}\} \)
This last set is written more simply $\{1, 2, 3\}$.

Given a set $A$ of objects in some domain and an object $x$, we write
$x \in A$ to say that $x$ is an element of $A$. Using set-builder
notation, we can define a number of common sets and operations. The
/empty set/, $\emptyset$, is the set with no elements:
\begin{equation*}
\emptyset = \{ x \st \mbox{false} \}
\end{equation*}
Dually, we can define the /universal set/, $\mathcal U$, to be the set
consisting of every element of the domain:
\begin{equation*}
\mathcal U = \{ x \st \mbox{true} \}
\end{equation*}
Given to sets $A$ and $B$, we define their /union/ to be the set of
elements in either one:
\begin{equation*}
A \cup B = \{ x \st \mbox{$x \in A$ or $x \in B$} \}
\end{equation*}
And we define their /intersection/ to be the set of elements of both:
\begin{equation*}
A \cap B = \{ x \st \mbox{$x \in A$ and $x \in B$} \}
\end{equation*}
We define the /complement/ of a set of $A$ to be the set of elements
that are not in $A$:
\begin{equation*}
\overline A = \{ x \st \mbox{$x \notin A$} \}
\end{equation*}
We define the /set difference/ of two sets $A$ and $B$ to be the set
of elements in $A$ but not $B$:
\begin{equation*}
A \setminus B = \{ x \st \mbox{$x \in A$ and $x \notin B$} \}
\end{equation*}

Two sets are said to be equal if they have exactly the same
elements. If $A$ and $B$ are sets, $A$ is said to be a /subset/ of
$B$, written $A \subseteq B$, if every element of $A$ is an element of
$B$. Notice that $A$ is equal to $B$ if and only if $A$ is a subset of
$B$ and $B$ is a subset of $A$.

Notice also that just everything we have said about sets so far is
readily representable in symbolic logic. We can render the defining
properties of the basic sets and constructors as follows:
\begin{align*}
& \fa x (x \notin \emptyset) \\
& \fa x (x \in \mathcal U) \\
& \fa x (x \in A \cup B \liff x \in A \vee x \in B) \\
& \fa x (x \in A \cap B \liff x \in A \wedge x \in B) \\
& \fa x (x \in \overline A \liff x \notin A) \\
& \fa x (x \in A \setminus B \liff x \in A \wedge x \notin B)
\end{align*}
The assertion that $A$ is a subset of $B$ can be written $\fa x (x \in
A \to x \in B)$, and the assertion that $A$ is equal to be can be
written $\fa x (x \in A \liff x \in B)$. These are all
\emph{universal} statements, that is, statements with universal
quantifiers in front, followed by basic assertions and propositional
connectives. What this means is that reasoning about sets formally
often amounts to using nothing more than the rules for the universal
quantifier together with the rules for propositional logic. You should
by now be able to discern this formal structure underlying /informal/
proofs as well. Here are two examples.

-----

Let $A, B, C, \ldots$ denotes sets of elements of some domain, $X$.

*Theorem*. $A \cap (B \cup C) = (A \cap B) \cup (A \cap C)$.

*Proof*. Suppose $x$ is in $A \cap (B \cup C)$. Then $x$ is in $A$,
and either $x$ is in $B$ or $x$ is in $C$. In the first case, $x$ is
in $A$ and $B$, and hence in $A \cap B$. In the second case, $x$ is in
$A$ and $C$, and hence $A \cap C$. Either way, we have that $x$ is in
$(A \cap B) \cup (A \cap C)$.

Conversely, suppose $x$ is in $(A \cap B) \cup (A \cap C)$. There are
now two cases. 

First, suppose $x$ is in $A \cap B$. Then $x$ is in both $A$ and
$B$. Since $x$ is in $B$, it is also in $B \cup C$, and so $x$ is in
$A \cap (B \cup C)$.

The second case is similar: suppose $x$ is in $A \cap C$. Then $x$ is
in both $A$ and $C$, and so also in $B \cup C$. Hence, in this case
also, $x$ is in $A \cap (B \cup C)$, as required.

-----

-----
*Theorem*. $(A \setminus B) \setminus C = A \setminus (B \cup C)$.

*Proof*. Suppose $x$ is in $(A \setminus B) \setminus C$. Then $x$ is
in $A \setminus B$ but not $C$, and hence it is in $A$ but not $B$ or
$C$. This means that $x$ is in $A$ but not $B \cup C$, and so in $A
\setminus (B \cup C)$.

Conversely, suppose $x$ is in $A \setminus (B \cup C)$. Then $x$ is in
$A$, but not in $B \cup C$. In particular, $x$ is in neither $B$ nor
$C$, because otherwise it would be in $B \cup C$. So $x$ is in $A
\setminus B$, and hence $(A \setminus B) \setminus C$.

-----

You can carry out such reasoning in Lean, using methods you have
already seen. For any type =X=, Lean gives us a type, =set X=, of sets
of elements of =X=, with the element-of relation =x ∈ A=. We need only
import the library file =data.set= and open the "namespace" set to
have the notions and notations made available to us.
#+BEGIN_SRC lean
import data.set
open set

variable {X : Type}
variables A B C : set X
#+END_SRC
We have made the type variable =X= implicit, because it can usually be
inferred from context. The following pattern can be used to show that
=A= is a subset of =B=:
#+BEGIN_SRC lean
import data.set
open set

variable {X : Type}
variables A B C : set X

-- BEGIN
example : A ⊆ B :=
take x,
assume H : x ∈ A,
show x ∈ B, from sorry
-- END
#+END_SRC
And the following pattern be used to show that =A= and =B= are equal:
#+BEGIN_SRC lean
import data.set
open set

variable {X : Type}
variables A B C : set X

-- BEGIN
example : A = B :=
eq_of_subset_of_subset
  (take x,
    assume H : x ∈ A,
    show x ∈ B, from sorry)
  (take x,
    assume H : x ∈ B,
    show x ∈ A, from sorry)
-- END
#+END_SRC
Moreover, Lean supports the following nifty feature: all of the
equivalences above are considered to hold "definitionally," which is
to say, in most situations you can treat and the left- and
right-hand-sides as being the same. In other words, you can act as
though the expression =x ∈ A ∩ B= is no different from =x ∈ A ∧ x ∈
B=, and similarly for the other constructors.

#+BEGIN_SRC lean
import data.set
open set

variable {X : Type}
variables A B C : set X

-- BEGIN
example : ∀ x, x ∈ A → x ∈ B → x ∈ A ∩ B :=
take x, 
suppose x ∈ A,
suppose x ∈ B,
show x ∈ A ∩ B, from and.intro `x ∈ A` `x ∈ B`

example : ∀ x : X, x ∉ ∅ :=
take x, 
suppose x ∈ ∅, 
show false, from this
-- END
#+END_SRC
In the second example, we annotated =x= with its type, =X=, because
otherwise there is not enough information for Lean to infer which
"empty set" we have in mind. You can type the symbols =⊆=, =∅=, =∪=,
=∩=, =\= as =\subeq= =\empty=, =\un=, =\i=, and =\\=,
respectively. The universal set is denoted =univ=, and set
complementation is denoted with a negation symbol.

The identifications above make it easy to prove some containment
relations:
#+BEGIN_SRC lean
import data.set
open set

variable {X : Type}
variables A B C : set X

-- BEGIN
example : A \ B ⊆ A :=
take x,
suppose x ∈ A \ B,
show x ∈ A, from and.left this

example : A \ B ⊆ -B :=
take x,
suppose x ∈ A \ B,
have x ∉ B, from and.right this,
show x ∈ -B, from this
-- END
#+END_SRC
Here is the proof of the first identity that we proved informally
above:
#+BEGIN_SRC lean
import data.set
open set

variable {X : Type}
variables A B C : set X

-- BEGIN
example : A ∩ (B ∪ C) = (A ∩ B) ∪ (A ∩ C) :=
eq_of_subset_of_subset
  (take x,
    assume H : x ∈ A ∩ (B ∪ C),
    have x ∈ A, from and.left H,
    have x ∈ B ∪ C, from and.right H,
    or.elim (`x ∈ B ∪ C`)
      (suppose x ∈ B,
        have x ∈ A ∩ B, from and.intro `x ∈ A` `x ∈ B`,
        show x ∈ (A ∩ B) ∪ (A ∩ C), from or.inl this)
      (suppose x ∈ C,
        have x ∈ A ∩ C, from and.intro `x ∈ A` `x ∈ C`,
        show x ∈ (A ∩ B) ∪ (A ∩ C), from or.inr this))
  (take x,
    suppose x ∈ (A ∩ B) ∪ (A ∩ C),
    or.elim this
      (assume H : x ∈ A ∩ B,
        have x ∈ A, from and.left H,
        have x ∈ B, from and.right H,
        have x ∈ B ∪ C, from or.inl this,
        show x ∈ A ∩ (B ∪ C), from and.intro `x ∈ A` this)
      (assume H : x ∈ A ∩ C,
        have x ∈ A, from and.left H,
        have x ∈ C, from and.right H,
        have x ∈ B ∪ C, from or.inr this,
        show x ∈ A ∩ (B ∪ C), from and.intro `x ∈ A` this))
-- END
#+END_SRC
Notice that it is considerably longer than the informal proof above,
because we have spelled out every last detail, though it may not be
more readable. Keep in mind that you can always write long proofs
incrementally, using =sorry=. You can also break up long proofs into
smaller pieces:
#+BEGIN_SRC lean
import data.set
open set

variable {X : Type}
variables A B C : set X

-- BEGIN
proposition inter_union_subset : A ∩ (B ∪ C) ⊆ (A ∩ B) ∪ (A ∩ C) :=
take x,
assume H : x ∈ A ∩ (B ∪ C),
have x ∈ A, from and.left H,
have x ∈ B ∪ C, from and.right H,
or.elim (`x ∈ B ∪ C`)
  (suppose x ∈ B,
    have x ∈ A ∩ B, from and.intro `x ∈ A` `x ∈ B`,
    show x ∈ (A ∩ B) ∪ (A ∩ C), from or.inl this)
  (suppose x ∈ C,
    have x ∈ A ∩ C, from and.intro `x ∈ A` `x ∈ C`,
    show x ∈ (A ∩ B) ∪ (A ∩ C), from or.inr this)

proposition inter_union_inter_subset : (A ∩ B) ∪ (A ∩ C) ⊆ A ∩ (B ∪ C) :=
take x,
suppose x ∈ (A ∩ B) ∪ (A ∩ C),
or.elim this
  (assume H : x ∈ A ∩ B,
    have x ∈ A, from and.left H,
    have x ∈ B, from and.right H,
    have x ∈ B ∪ C, from or.inl this,
    show x ∈ A ∩ (B ∪ C), from and.intro `x ∈ A` this)
  (assume H : x ∈ A ∩ C,
    have x ∈ A, from and.left H,
    have x ∈ C, from and.right H,
    have x ∈ B ∪ C, from or.inr this,
    show x ∈ A ∩ (B ∪ C), from and.intro `x ∈ A` this)

example : A ∩ (B ∪ C) = (A ∩ B) ∪ (A ∩ C) :=
eq_of_subset_of_subset
  (inter_union_subset A B C)
  (inter_union_inter_subset A B C)
-- END
#+END_SRC
Notice that the two propositions depend on the variables =A=, =B=, and
=C=, which have to be supplied as arguments when they are
applied. They also depend on the underlying type, =X=, but because the
variable =X= was marked implicit, Lean figures it out from the
context.








